{
  "id": "gesture-recognizer",
  "titleShort": "Gesture\nRecognition",
  "titleLong": "Gesture Segmenter and Recognizer",
  "urls": {
    "github": "https://github.com/levilindsey/stroke-recognition"
  },
  "jobTitle": "",
  "location": "",
  "date": {
    "start": "9/2011",
    "end": "7/2013"
  },
  "categories": [
    "school",
    "research",
    "c-sharp",
    "app",
    "pen"
  ],
  "images": [
    {
      "fileName": "canvas-ink-sigma-instance.png",
      "description": "The program with a sigma shape drawn by the user. The system parameters can be seen on the right. The recognizer in this case has been trained on the sample student data with a hold out of first and sixth instances of each shape from each user. The system recognizes the current canvas ink as a sigma shape."
    },
    {
      "fileName": "directional-bitmaps-sigma-instance.png",
      "description": "The directional pixel values for the ink shown in the previous image."
    },
    {
      "fileName": "directional-bitmaps-sigma-template.png",
      "description": "The directional bitmaps for the sigma shape class template. More intense coloration represents higher probabilities."
    },
    {
      "fileName": "directional-bitmaps-1-2-instance-and-template.png",
      "description": "The directional pixel values for a holdout shape overlaid on top of the directional bitmaps for the shape class template to which it was matched."
    },
    {
      "fileName": "recognition-stats-1-2-instance.png",
      "description": "The recognition details for the shape instance shown in the previous image."
    },
    {
      "fileName": "average-results.png",
      "description": "A confusion matrix showing the average results from an 18-fold cross-validation with single-user holdouts."
    }
  ],
  "videos": [
    {
      "videoHost": "youtube",
      "id": "xxBeSKijSSw",
      "description": "A walkthrough of Levi's stroke segmentation functionality."
    }
  ],
  "content": "_Levi developed a novel algorithm for real-time gesture recognition from ink data. This was extended from work done in\r\na UCR course on Pen-Based Computing algorithms and techniques._\r\n\r\n## An Inductive Image-Based Recognizer Using Directional Bitmap Templates\r\n\r\n### Contents\r\n\r\n- The Algorithm\r\n- Strengths\r\n- Weaknesses\r\n- Improvements\r\n- Performance\r\n- Additional Features\r\n\r\n### The Algorithm\r\n\r\nThe general idea of the algorithm is to first create four template bitmaps to represent the ink directional\r\nprobability of a given shape class, then an unknown shape instance is classified as the class whose directional\r\ntemplates it most closely matches.\r\n\r\n#### Preprocessing\r\n\r\nFirst, angle values are computed for all points in all strokes in a given shape instance. These angles are based off\r\nzero degrees along the horizontal axis. The angle value for a point is calculated as the average of the angles of the\r\nline segments connecting that point to its previous and next neighbors. These angles are then convoluted with a\r\nGaussian smoothing kernel.\r\n\r\nNext, the given shape instance is uniformly scaled and translated so that its x and y coordinate values range from 0\r\nto 1. It is also translated so that it is centered in this hypothetical, square, 1x1 canvas.\r\n\r\nDirectional pixel values are then computed for the given shape instance. There are four directional components\r\nassociated with each pixel&mdash;the lines along 0&deg;, 45&deg;, 90&deg;, and 135&deg;. The value of a point for each\r\nof these four directions is 1 if the angle is different by 0&deg;, 0 if the angle is different by 45&deg; degrees or\r\nmore, and linearly interpolated between 0 and 1 for angles differing by 0&deg;-45&deg;. Note that these directions\r\nalso match with their opposites; i.e., if a point has an angle of 215&deg;, then it has a difference of 0&deg; with\r\nthe 45&deg; line, and its value for its 45&deg; directional pixel is 1.\r\n\r\nThe entire bitmap region is not stored for each shape instance; in order to save space and time, a mapping from pixel\r\nindices to directional intensity values is created, and this mapping contains a key for a given pixel if and only if\r\nthe shape instance contains a point in that pixel. There are actually four such mappings for each shape instance&mdash;\r\none for each of the four directions. These mappings are created by looping over each of the points, determining in\r\nwhich pixel a point lies, and storing the four directional values of this point at this pixel index within the four\r\nmappings. If multiple points in a shape instance have values for the same direction in the same pixel, then the\r\nlargest value is saved.\r\n\r\nThe discretization of ink means that we have two special cases to consider: when a single pixel contains multiple\r\nconsecutive points, and when the line segment between two consecutive points intersects a pixel in which neither point\r\nactually lies. The former case is actually handled well with the aforementioned policy of saving a pixel's maximal\r\nintensity value for each direction. An alternative approach for this could have been to use the average angle values\r\nfor consecutive points lying within the same pixel, but this causes a good deal of information to be lost within\r\npixels containing high curvature&mdash;i.e., corners. The latter case could be handled robustly by calculating the\r\nintermediate pixels via the Bresenham line algorithm, but the lost pixels become less significant with more training\r\nexamples. Also, a 3x3 Gaussian smoothing kernel is used to smooth the final values of the templates. However, these\r\ntwo points do not address the lost pixels from an unknown shape instance being recognized, and further research could\r\nbe performed to determine whether the application of the Bresenham line algorithm would increase recognition accuracy.\r\n\r\n#### Training\r\n\r\nAfter each shape instance has been preprocessed, actually creating the templates is a simple process. For each shape\r\nclass, four complete bitmaps are created&mdash;one for each direction&mdash;and then all of the pixel intensity values\r\nfor each of the training shape instances are added together into the appropriate bitmaps. Each pixel in each bitmap is\r\nthen normalized by the number of training instances for the given shape class template. Finally, a 3x3 Gaussian\r\nsmoothing kernel is used to smooth the final values of each of the directional bitmaps for each template.\r\n\r\n#### Recognition\r\n\r\nTo recognize a given unknown shape instance, a simple distance metric is used, and the shape is classified as \r\nwhichever class yields the smallest distance. This distance between a shape instance and a class template is computed \r\nas\r\n\r\n![Shape-class distance equation][shape-class-distance-equation-image]\r\n\r\nwhere _I_ is the list of the pixel indices&mdash;i.e., keys&mdash;in the pixel indices to directional intensity values\r\nmappings, _s<sub>&theta;i<\/sub>_ is the directional intensity value from the &theta; directional mapping of the pixel\r\nat index _i_ for the unknown shape instance, _t<sub>&theta;i<\/sub>_ is the directional intensity value from the\r\n&theta; directional bitmap of the pixel at index _i_ for the shape class template, _n<sub>s<\/sub>_ is the number of\r\npixels containing ink for the unknown shape instance, _n<sub>t<\/sub>_ is the average number of pixels containing ink\r\nfor the shape class template, and _w_ is a weight parameter.\r\n\r\nThe term relating to the number of pixels containing ink is important, because this distance metric only considers\r\npixels which are covered by the unknown shape instance. To understand why this is a problem, consider the example of\r\nthe unknown shape instance being the letter P, and there are templates both for the letter P and the letter R.\r\nBecause the distance only considers the pixels from the shape instance P, the P and R templates will be found to have\r\nroughly the same distance. This term for the number of pixels containing ink allows the distance metric to match the P\r\nshape instance more closely to the P template than the R template.\r\n\r\nIt may seem that rather than using this term for the number of pixels containing ink, that the distance metric could \r\nsimply sum over all of the pixels in the template bitmap rather than only over the pixels covered by the shape \r\ninstance, but this leads to its own problem. This would mean that whichever class template contains the least\r\nink&mdash;in our case '-'&mdash;would nearly always be found to have the lowest distance.\r\n\r\n#### Parameters\r\n\r\n_w_ = 0.09\r\ntemplate side length (they are square) = 14\r\nnumber of smoothing iterations for the templates = 3\r\nnumber of smoothing iterations for the point angle values = 1\r\n\r\nThese values have been selected by hand.\r\n\r\n### Performance\r\n\r\nIn order to test this algorithm, a shape collection was compiled from 18 people each drawing 15 shapes 5 times with a\r\nfew instances being lost due to collection error.\r\n\r\nThen an 18-fold cross-validation was performed with single-user hold outs. The averages from this test are presented\r\nin this confusion matrix.\r\n\r\n![Average results][average-results-image]\r\n\r\n_***NOTE: this screen shot should instead say \"18-fold\"**_\r\n\r\n### Strengths\r\n\r\nThe largest strength of this recognition algorithm is that it is extremely fast both to train and to recognize. It \r\ntook, on average, 0.36 to perform the 18-fold cross-validation, 0.02 seconds to train, and 0.00006 seconds to \r\nrecognize a shape instance.\r\n\r\nThis algorithm is scale invariant.\r\n\r\n### Weaknesses\r\n\r\nThis algorithm is rotationally variant, so it would not perform well with a system in which rotation mattered.\r\n\r\nThis algorithm does not fully take into account the conditional probabilities of the ink. The templates naturally \r\nrepresent a form of Gaussian probability for ink around a segment of the shape class&mdash;i.e., there is a higher \r\nprobability of the ink in an instance of the shape class lying in the center of the segment of the template than off \r\nto either side of the segment. However, given that a point in an instance of the shape class does lie off to one side \r\nof a segment of the shape class template, it is much more likely that the next point also will lie off to that side, \r\nand much less likely that the next point will lie off to the other side. This algorithm does not take advantage of \r\nthis conditional probability.\r\n\r\n### Improvements\r\n\r\nThis algorithm could be extended to become rotationally invariant. This could possibly be done by rotating each shape \r\ninstance according to an indicative angle from the centroid to the furthest point from the centroid.\r\n\r\nThe conditional ink probability&mdash;addressed in the weaknesses section&mdash;could be taken advantage of with a\r\n\"super pixel\" scheme. In this scheme, each pixel in each directional bitmap could contain four additional mxm\r\nsub-bitmaps of pixel values. These sub-bitmaps would represent the conditional directional ink probabilities of the\r\nneighbors of the given center pixel. Adapting the training of the templates for these bitmaps of super pixels and the\r\ndistance metric would be a fairly straightforward extension of their current versions. However, this super-pixel\r\nscheme would have a much higher time and space complexity.\r\n\r\n### Additional Features\r\n\r\n![Directional bitmaps for the sigma-class template][directional-bitmaps-sigma-template-image]\r\n\r\nThis shows the directional bitmaps for the sigma shape class template. More intense coloration represents higher probabilities.\r\n\r\n![The original ink on the canvas for an instance of the sigma shape][canvas-ink-sigma-instance-image]\r\n\r\nThis shows the program with a sigma shape drawn by the user. The system parameters can be seen on the right. The recognizer in this case has been trained on the sample student data with a hold out of first and sixth instances of each shape from each user. The system recognizes the current canvas ink as a sigma shape.\r\n\r\n![Directional bitmaps showing an instance of the sigma shape][directional-bitmaps-sigma-instance-image]\r\n\r\nThis shows the directional pixel values for the ink shown in the previous image.\r\n\r\n![Directional bitmaps showing data for both an instance and the template of the 1\/2 shape][directional-bitmaps-1-2-instance-and-template-image]\r\n\r\nThis shows the directional pixel values for a holdout shape overlaid on top of the directional bitmaps for the shape class template to which it was matched.\r\n\r\n![Recognition statistics for an instance of the 1\/2 shape][recognition-stats-1-2-instance-image]\r\n\r\nThis shows the recognition details for the shape instance shown in the previous image.\r\n\r\n\r\n[shape-class-distance-equation-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/shape-class-distance-equation.png\r\n[average-results-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/average-results.png\r\n[directional-bitmaps-sigma-template-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/directional-bitmaps-sigma-template.png\r\n[canvas-ink-sigma-instance-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/canvas-ink-sigma-instance.png\r\n[directional-bitmaps-sigma-instance-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/directional-bitmaps-sigma-instance.png\r\n[directional-bitmaps-1-2-instance-and-template-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/directional-bitmaps-1-2-instance-and-template.png\r\n[recognition-stats-1-2-instance-image]: https:\/\/s3-us-west-2.amazonaws.com\/levi-portfolio-media\/gesture-recognizer\/recognition-stats-1-2-instance.png"
}